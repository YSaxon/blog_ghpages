<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Yaakov Saxon's Security Blog</title><link href="https://blog.stepaheadcyber.com/" rel="alternate"></link><link href="https://blog.stepaheadcyber.com/feeds/all.atom.xml" rel="self"></link><id>https://blog.stepaheadcyber.com/</id><updated>2024-08-06T00:00:00-04:00</updated><entry><title>Why adding report-to causes CSP reporting to fail over HTTP</title><link href="https://blog.stepaheadcyber.com/why-adding-report-to-causes-csp-reporting-to-fail-over-http.html" rel="alternate"></link><published>2024-08-06T00:00:00-04:00</published><updated>2024-08-06T00:00:00-04:00</updated><author><name>Yaakov Saxon</name></author><id>tag:blog.stepaheadcyber.com,2024-08-06:/why-adding-report-to-causes-csp-reporting-to-fail-over-http.html</id><summary type="html">&lt;p&gt;I recently was trying to improve the CSP headers on an application, so I get it set up running over http on localhost. I noticed very strangely that the policy itself worked fine, and reports were sent when I only included the older report-uri field. But if I included the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I recently was trying to improve the CSP headers on an application, so I get it set up running over http on localhost. I noticed very strangely that the policy itself worked fine, and reports were sent when I only included the older report-uri field. But if I included the newer report-to field in the CSP header, then although the CSP violations continued to be noted in the browser console, they were not sent to the reporting endpoint.&lt;/p&gt;
&lt;p&gt;It turns out that the HTTP is the problem.&lt;/p&gt;
&lt;p&gt;CSP headers are supported over HTTP (which is why the policy itself works) as are both the report-uri and report-to syntaxes, but the newer headers that define report-to endpoints are NOT supported under HTTP.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A browser that supports the newer report-to syntax will always use that in preference to the older report-uri syntax&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;It only falls back to report-uri if there is no report-to specified (or if the browser doesn't support report-to)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;If report-to is specified and supported, but the endpoint group is not defined, the report will simply fail&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The headers that define the report-to endpoint groups (there are actually two, the never fully implemented and now deprecated Report-To, and the even newer Reporting-Endpoints) are only parsed over HTTPS&lt;/li&gt;
&lt;li&gt;So the browser will see the report-to specification and decide to send to an endpoint group by that name, but that endpoint group will not be defined, and the report will fail&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can see this in Chrome by going to DevTools -&amp;gt; Application -&amp;gt; Reporting API. You will see no endpoint groups defined if you are running over HTTP, and the report will stay listed as queued.
(Note that the Endpoints list does not seem to populate with the Report-To header, only the Reporting-Endpoints header even over HTTPS, but even with Report-To you will see that the report is eventually sent if you are running over HTTPS)&lt;/p&gt;</content><category term="Curiousities"></category></entry><entry><title>Signed JWT Token strings are not unique</title><link href="https://blog.stepaheadcyber.com/signed-jwt-token-strings-are-not-unique.html" rel="alternate"></link><published>2024-07-25T00:00:00-04:00</published><updated>2024-07-25T00:00:00-04:00</updated><author><name>Yaakov Saxon</name></author><id>tag:blog.stepaheadcyber.com,2024-07-25:/signed-jwt-token-strings-are-not-unique.html</id><summary type="html">&lt;p&gt;I just learned the hard way that the last char of a JWT signature can be modified and still be valid. After a lot of manual debugging, I figured out the hard way that it is in fact the normal behaviour for JWTs with certain signature types, and has to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I just learned the hard way that the last char of a JWT signature can be modified and still be valid. After a lot of manual debugging, I figured out the hard way that it is in fact the normal behaviour for JWTs with certain signature types, and has to do with the base64 encoding implementation. &lt;a href="https://stackoverflow.com/a/58500239"&gt;Here&lt;/a&gt; is the best explanation I've found. Essentially in JWT base64 decoding, if there are extra bits, they are ignored. So for the n bits that are ignored in a signature, there are 2^n possible valid signatures. It occured to me that there is an interesting consequence of this, that if you ever wanted to revoke/block a particular JWT token, you could not simply blacklist the token's value, as there will still be 2^n-1 other valid strings encoding the same signed JWT token.&lt;/p&gt;
&lt;p&gt;I could imagine this being relevant if a long-lived high-profile JWT token leaked publically. The obvious fix, blacklisting that leaked token, would also be utterly insufficient!
(Knowing about this obscure quirk, you can easily accomplish the same thing correctly by blacklisting and comparing the token[:-1] instead of the full string)&lt;/p&gt;</content><category term="Curiousities"></category></entry><entry><title>My First Test Post</title><link href="https://blog.stepaheadcyber.com/my-first-test-post.html" rel="alternate"></link><published>2023-07-05T00:00:00-04:00</published><updated>2023-07-05T00:00:00-04:00</updated><author><name>Yaakov Saxon</name></author><id>tag:blog.stepaheadcyber.com,2023-07-05:/my-first-test-post.html</id><content type="html">&lt;p&gt;This is a test post.&lt;/p&gt;</content><category term="Misc"></category></entry><entry><title>Reverse Engineering Legu Encryption</title><link href="https://blog.stepaheadcyber.com/reverse-engineering-legu-encryption.html" rel="alternate"></link><published>2023-07-05T00:00:00-04:00</published><updated>2023-07-05T00:00:00-04:00</updated><author><name>Yaakov Saxon</name></author><id>tag:blog.stepaheadcyber.com,2023-07-05:/reverse-engineering-legu-encryption.html</id><summary type="html">&lt;p&gt;I recently came across an Android APK that was protected by an obfuscator made by the Chinese tech company Tencent, called Legu. Thankfully, there was a repo available to reverse the obfuscation, but it was out-of-date with respect to the encryption. Specifically, the repo said it supported up to 4 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I recently came across an Android APK that was protected by an obfuscator made by the Chinese tech company Tencent, called Legu. Thankfully, there was a repo available to reverse the obfuscation, but it was out-of-date with respect to the encryption. Specifically, the repo said it supported up to 4.0.1.18, and the version I was seeing was 4.0.1.31. Also, the dependencies were pretty difficult to use.&lt;/p&gt;
&lt;p&gt;The TLDR is that I reverse engineered the new encryption scheme (it's now using ChaCha20) and the new key derivation scheme (a multi step process involving two hardcoded keys being altered in subtle ways, and one decoy key not used at all), and updated and published a fork at [https://github.com/YSaxon/legu_unpacker_2023].&lt;/p&gt;
&lt;p&gt;But you won't always find the version you need there, if only because Tencent is likely to continue to update the keys. So I wrote up the &lt;em&gt;process&lt;/em&gt; of reverse engineering the encryption, so that it can always be updated in the future.&lt;/p&gt;
&lt;p&gt;You can find that writeup &lt;a href="https://github.com/YSaxon/legu_unpacker_2023/blob/master/reverse_engineering_tips/reverse_engineering_tips.md"&gt;here&lt;/a&gt;&lt;/p&gt;</content><category term="Hacking"></category></entry></feed>